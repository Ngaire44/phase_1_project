{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "163bbf2d",
   "metadata": {},
   "source": [
    "# Aviation Risk Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f0afe3",
   "metadata": {},
   "source": [
    "## üìä Data-Driven Strategy to entering the aviation industry\n",
    "This project uses the National Transportation Safety Board aviation accident data from 1962 to 2023 in United States and international waters. We will use this to identify strategic opportunities, risks and patterns.\n",
    "\n",
    "Through exploratory data analysis, trends and visualizations, we will give concrete data-driven business recommendations. This will help investors, insurers assess the risk exposurers and make informed decisions that are low risk.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde27d70",
   "metadata": {},
   "source": [
    "## ‚ùì Key Business Questions\n",
    "As we seek the answers to the questions below, the questions will guide the direction of my project\n",
    "1. Which aircraft make are least frequently involved in accidents\n",
    "    - This helps decide on the make or manufacturers(amateur built)\n",
    "2. What are the most common causes of aviation accidents\n",
    "    - This helps to understand risk trends, are newer models safer than older one\n",
    "3. What percentage of accidents are survivable and what factors influence survivability?\n",
    "    - Here, we will check on engines, weather\n",
    "4. How do accident rates vary by operator type (commercial vs private)\n",
    "    - This help to decide the aviation sector to indulge in\n",
    "5. Are there seasonal patterns in aviation accidents\n",
    "    - This helps in weather contingency planning\n",
    "6. What factors contribute to fatal accidents(weather, broad phase of flight)\n",
    "    - Helps decide on aircraft specs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1266f55a",
   "metadata": {},
   "source": [
    "## üìÇData Understanding\n",
    "\n",
    "In this section, we examine the datasets used in the project from the National Transportation Safety Board aviation accident data from [Our Dataset](https://www.kaggle.com/datasets/khsamaha/aviation-accident-database-synopses). We familiarize ourselves with the dataset structure. We thoroughly go through the columns and rows, identify missing data, categorical grouping and data range.\n",
    "\n",
    "We analyze the data quality by checking for completeness,consistency, uniqueness and distributions. A clean dataset gives clear and accurate analysis and visualizations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5d7c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66044e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the csv file AviationData\n",
    "AviData = pd.read_csv('Data\\AviationData.csv', encoding= 'latin1', low_memory= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b3a1ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event.Id</th>\n",
       "      <th>Investigation.Type</th>\n",
       "      <th>Accident.Number</th>\n",
       "      <th>Event.Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Airport.Code</th>\n",
       "      <th>Airport.Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Purpose.of.flight</th>\n",
       "      <th>Air.carrier</th>\n",
       "      <th>Total.Fatal.Injuries</th>\n",
       "      <th>Total.Serious.Injuries</th>\n",
       "      <th>Total.Minor.Injuries</th>\n",
       "      <th>Total.Uninjured</th>\n",
       "      <th>Weather.Condition</th>\n",
       "      <th>Broad.phase.of.flight</th>\n",
       "      <th>Report.Status</th>\n",
       "      <th>Publication.Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001218X45444</td>\n",
       "      <td>Accident</td>\n",
       "      <td>SEA87LA080</td>\n",
       "      <td>1948-10-24</td>\n",
       "      <td>MOOSE CREEK, ID</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Personal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Cruise</td>\n",
       "      <td>Probable Cause</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001218X45447</td>\n",
       "      <td>Accident</td>\n",
       "      <td>LAX94LA336</td>\n",
       "      <td>1962-07-19</td>\n",
       "      <td>BRIDGEPORT, CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Personal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Probable Cause</td>\n",
       "      <td>19-09-1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20061025X01555</td>\n",
       "      <td>Accident</td>\n",
       "      <td>NYC07LA005</td>\n",
       "      <td>1974-08-30</td>\n",
       "      <td>Saltville, VA</td>\n",
       "      <td>United States</td>\n",
       "      <td>36.922223</td>\n",
       "      <td>-81.878056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Personal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IMC</td>\n",
       "      <td>Cruise</td>\n",
       "      <td>Probable Cause</td>\n",
       "      <td>26-02-2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001218X45448</td>\n",
       "      <td>Accident</td>\n",
       "      <td>LAX96LA321</td>\n",
       "      <td>1977-06-19</td>\n",
       "      <td>EUREKA, CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Personal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IMC</td>\n",
       "      <td>Cruise</td>\n",
       "      <td>Probable Cause</td>\n",
       "      <td>12-09-2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20041105X01764</td>\n",
       "      <td>Accident</td>\n",
       "      <td>CHI79FA064</td>\n",
       "      <td>1979-08-02</td>\n",
       "      <td>Canton, OH</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Personal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VMC</td>\n",
       "      <td>Approach</td>\n",
       "      <td>Probable Cause</td>\n",
       "      <td>16-04-1980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Event.Id Investigation.Type Accident.Number  Event.Date  \\\n",
       "0  20001218X45444           Accident      SEA87LA080  1948-10-24   \n",
       "1  20001218X45447           Accident      LAX94LA336  1962-07-19   \n",
       "2  20061025X01555           Accident      NYC07LA005  1974-08-30   \n",
       "3  20001218X45448           Accident      LAX96LA321  1977-06-19   \n",
       "4  20041105X01764           Accident      CHI79FA064  1979-08-02   \n",
       "\n",
       "          Location        Country   Latitude   Longitude Airport.Code  \\\n",
       "0  MOOSE CREEK, ID  United States        NaN         NaN          NaN   \n",
       "1   BRIDGEPORT, CA  United States        NaN         NaN          NaN   \n",
       "2    Saltville, VA  United States  36.922223  -81.878056          NaN   \n",
       "3       EUREKA, CA  United States        NaN         NaN          NaN   \n",
       "4       Canton, OH  United States        NaN         NaN          NaN   \n",
       "\n",
       "  Airport.Name  ... Purpose.of.flight Air.carrier Total.Fatal.Injuries  \\\n",
       "0          NaN  ...          Personal         NaN                  2.0   \n",
       "1          NaN  ...          Personal         NaN                  4.0   \n",
       "2          NaN  ...          Personal         NaN                  3.0   \n",
       "3          NaN  ...          Personal         NaN                  2.0   \n",
       "4          NaN  ...          Personal         NaN                  1.0   \n",
       "\n",
       "  Total.Serious.Injuries Total.Minor.Injuries Total.Uninjured  \\\n",
       "0                    0.0                  0.0             0.0   \n",
       "1                    0.0                  0.0             0.0   \n",
       "2                    NaN                  NaN             NaN   \n",
       "3                    0.0                  0.0             0.0   \n",
       "4                    2.0                  NaN             0.0   \n",
       "\n",
       "  Weather.Condition  Broad.phase.of.flight   Report.Status Publication.Date  \n",
       "0               UNK                 Cruise  Probable Cause              NaN  \n",
       "1               UNK                Unknown  Probable Cause       19-09-1996  \n",
       "2               IMC                 Cruise  Probable Cause       26-02-2007  \n",
       "3               IMC                 Cruise  Probable Cause       12-09-2000  \n",
       "4               VMC               Approach  Probable Cause       16-04-1980  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first 5 rows\n",
    "AviData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dea0911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Event.Id', 'Investigation.Type', 'Accident.Number', 'Event.Date',\n",
       "       'Location', 'Country', 'Latitude', 'Longitude', 'Airport.Code',\n",
       "       'Airport.Name', 'Injury.Severity', 'Aircraft.damage',\n",
       "       'Aircraft.Category', 'Registration.Number', 'Make', 'Model',\n",
       "       'Amateur.Built', 'Number.of.Engines', 'Engine.Type', 'FAR.Description',\n",
       "       'Schedule', 'Purpose.of.flight', 'Air.carrier', 'Total.Fatal.Injuries',\n",
       "       'Total.Serious.Injuries', 'Total.Minor.Injuries', 'Total.Uninjured',\n",
       "       'Weather.Condition', 'Broad.phase.of.flight', 'Report.Status',\n",
       "       'Publication.Date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column names#\n",
    "AviData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdd4491a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 88889 entries, 0 to 88888\n",
      "Data columns (total 31 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Event.Id                88889 non-null  object \n",
      " 1   Investigation.Type      88889 non-null  object \n",
      " 2   Accident.Number         88889 non-null  object \n",
      " 3   Event.Date              88889 non-null  object \n",
      " 4   Location                88837 non-null  object \n",
      " 5   Country                 88663 non-null  object \n",
      " 6   Latitude                34382 non-null  object \n",
      " 7   Longitude               34373 non-null  object \n",
      " 8   Airport.Code            50249 non-null  object \n",
      " 9   Airport.Name            52790 non-null  object \n",
      " 10  Injury.Severity         87889 non-null  object \n",
      " 11  Aircraft.damage         85695 non-null  object \n",
      " 12  Aircraft.Category       32287 non-null  object \n",
      " 13  Registration.Number     87572 non-null  object \n",
      " 14  Make                    88826 non-null  object \n",
      " 15  Model                   88797 non-null  object \n",
      " 16  Amateur.Built           88787 non-null  object \n",
      " 17  Number.of.Engines       82805 non-null  float64\n",
      " 18  Engine.Type             81812 non-null  object \n",
      " 19  FAR.Description         32023 non-null  object \n",
      " 20  Schedule                12582 non-null  object \n",
      " 21  Purpose.of.flight       82697 non-null  object \n",
      " 22  Air.carrier             16648 non-null  object \n",
      " 23  Total.Fatal.Injuries    77488 non-null  float64\n",
      " 24  Total.Serious.Injuries  76379 non-null  float64\n",
      " 25  Total.Minor.Injuries    76956 non-null  float64\n",
      " 26  Total.Uninjured         82977 non-null  float64\n",
      " 27  Weather.Condition       84397 non-null  object \n",
      " 28  Broad.phase.of.flight   61724 non-null  object \n",
      " 29  Report.Status           82508 non-null  object \n",
      " 30  Publication.Date        75118 non-null  object \n",
      "dtypes: float64(5), object(26)\n",
      "memory usage: 21.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Information on the dataset\n",
    "AviData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7624af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88889, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of the dataset\n",
    "AviData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f546c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Schedule                  0.858453\n",
       "Air.carrier               0.812710\n",
       "FAR.Description           0.639742\n",
       "Aircraft.Category         0.636772\n",
       "Longitude                 0.613304\n",
       "Latitude                  0.613203\n",
       "Airport.Code              0.434699\n",
       "Airport.Name              0.406113\n",
       "Broad.phase.of.flight     0.305606\n",
       "Publication.Date          0.154924\n",
       "Total.Serious.Injuries    0.140737\n",
       "Total.Minor.Injuries      0.134246\n",
       "Total.Fatal.Injuries      0.128261\n",
       "Engine.Type               0.079616\n",
       "Report.Status             0.071786\n",
       "Purpose.of.flight         0.069660\n",
       "Number.of.Engines         0.068445\n",
       "Total.Uninjured           0.066510\n",
       "Weather.Condition         0.050535\n",
       "Aircraft.damage           0.035932\n",
       "Registration.Number       0.014816\n",
       "Injury.Severity           0.011250\n",
       "Country                   0.002542\n",
       "Amateur.Built             0.001147\n",
       "Model                     0.001035\n",
       "Make                      0.000709\n",
       "Location                  0.000585\n",
       "Event.Date                0.000000\n",
       "Accident.Number           0.000000\n",
       "Investigation.Type        0.000000\n",
       "Event.Id                  0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "To check missing values in percentage from large to small\n",
    "AviData.isna().mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c62f5e",
   "metadata": {},
   "source": [
    "## Observation\n",
    "\n",
    "- We have 31 columns and 88889 rows.\n",
    "- Most of our columns have categorical data; some of which we will have to change\n",
    "- Most of our columns have missing data, a few have more than 60% missing data\n",
    "\n",
    "#### Point to note\n",
    "We will have to go through each column to decide wether to replace or fill\n",
    "- We will use fillna() or replace()\n",
    "- We use 'unknown' for categorical data and mean or 0 for numerical data\n",
    "- We can also drop columns using dropna()\n",
    "\n",
    "#### Next step\n",
    " - We make a copy before any changes to preserve the original dataset\n",
    " - Go through each column and find if it's important in our analysis\n",
    " - Identify what to drop\n",
    " - \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "249dd67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88889, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#copy of the original data before we start dropping \n",
    "data = AviData.copy(deep=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85a64b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Event.Id', 'Investigation.Type', 'Accident.Number', 'Event.Date',\n",
       "       'Location', 'Country', 'Latitude', 'Longitude', 'Airport.Code',\n",
       "       'Airport.Name', 'Injury.Severity', 'Aircraft.damage',\n",
       "       'Aircraft.Category', 'Registration.Number', 'Make', 'Model',\n",
       "       'Amateur.Built', 'Number.of.Engines', 'Engine.Type', 'FAR.Description',\n",
       "       'Schedule', 'Purpose.of.flight', 'Air.carrier', 'Total.Fatal.Injuries',\n",
       "       'Total.Serious.Injuries', 'Total.Minor.Injuries', 'Total.Uninjured',\n",
       "       'Weather.Condition', 'Broad.phase.of.flight', 'Report.Status',\n",
       "       'Publication.Date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a05c6ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['event_id', 'investigation_type', 'accident_number', 'event_date',\n",
       "       'location', 'country', 'latitude', 'longitude', 'airport_code',\n",
       "       'airport_name', 'injury_severity', 'aircraft_damage',\n",
       "       'aircraft_category', 'registration_number', 'make', 'model',\n",
       "       'amateur_built', 'number_of_engines', 'engine_type', 'far_description',\n",
       "       'schedule', 'purpose_of_flight', 'air_carrier', 'total_fatal_injuries',\n",
       "       'total_serious_injuries', 'total_minor_injuries', 'total_uninjured',\n",
       "       'weather_condition', 'broad_phase_of_flight', 'report_status',\n",
       "       'publication_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize column names\n",
    "data.columns= data.columns.str.strip().str.lower().str.replace('.','_')\n",
    "data.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc53868",
   "metadata": {},
   "source": [
    "## üßº Data Cleaning\n",
    "\n",
    "The goal of data cleaning is to transform the raw dataset into a structured and reliable format suitable for analysis. Key steps included:\n",
    "Handle missing values, Drop columns with excessive missing data, Impute missing values using appropriate statistical or categorical strategies, Data Filtering, Remove irrelevant or incomplete records (e.g. non-aircraft incidents or missing key variables), Categorical Grouping, Group low-frequency entries under broader labels (e.g. \"Other\"), Data Type Correction, Convert date columns to proper datetime format, Ensure numerical columns were correctly typed for analysis, and Outlier Treatment.\n",
    "These steps ensure we have a clean, consistent, and relevant dataset to move forward with meaningful visualizations and business insights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffd0b240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_id                      0\n",
       "investigation_type            0\n",
       "accident_number               0\n",
       "event_date                    0\n",
       "location                     52\n",
       "country                     226\n",
       "latitude                  54507\n",
       "longitude                 54516\n",
       "airport_code              38640\n",
       "airport_name              36099\n",
       "injury_severity            1000\n",
       "aircraft_damage            3194\n",
       "aircraft_category         56602\n",
       "registration_number        1317\n",
       "make                         63\n",
       "model                        92\n",
       "amateur_built               102\n",
       "number_of_engines          6084\n",
       "engine_type                7077\n",
       "far_description           56866\n",
       "schedule                  76307\n",
       "purpose_of_flight          6192\n",
       "air_carrier               72241\n",
       "total_fatal_injuries      11401\n",
       "total_serious_injuries    12510\n",
       "total_minor_injuries      11933\n",
       "total_uninjured            5912\n",
       "weather_condition          4492\n",
       "broad_phase_of_flight     27165\n",
       "report_status              6381\n",
       "publication_date          13771\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check missing values in each column\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b087923f",
   "metadata": {},
   "source": [
    "### Dropping columns\n",
    "From data understanding above, we learned that most of our columns were missing values. We will drop all columns missing more than 15%. It may seem very extreme but we chose that percentage since also all of the other columns we don't need are in this percentage. It is important to note that analysis with more than 40% missingness may lead to biasness\n",
    " - Example: \n",
    " 1. Schedule and air carrier have more than 80% missing values, fillna with mode will bias analysis\n",
    " - We may keep far description and aircraft category by filling in unknown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbf765ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88889, 23)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#identify what to retain\n",
    "retain= ['far_description','aircraft_category']\n",
    "#Select the threshold for missing values\n",
    "threshold= 0.15 \n",
    "#find columns with 15% or more missing values\n",
    "dropped_all= data.columns[data.isna().mean()>=threshold]\n",
    "#exempt the columns to retain\n",
    "dropped=[col for col in dropped_all if col not in retain]\n",
    "#drop the identified columns\n",
    "data= data.drop(columns=dropped)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc52953",
   "metadata": {},
   "source": [
    "### Far description and aircraft category\n",
    "\n",
    "We will fill the missing values with unknown since most of the values are missing. Filling any other thing will affect the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb932017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fill retain with unknown\n",
    "[data[col].fillna('unknown', inplace=True)for col in retain]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71729d5",
   "metadata": {},
   "source": [
    "#### event_id\n",
    "#### Observation \n",
    "We will keep the event_id \n",
    "- It has no missing values\n",
    "- The difference in total and unique events is because some event_ids are similar\n",
    "- The other values in the rows are not all similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2eced83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 87951 unique events out of 88889 total events\n",
      "There are 0 missing events\n"
     ]
    }
   ],
   "source": [
    "#we check for duplicates in event_id\n",
    "missing_events= data['event_id'].isna().sum()\n",
    "unique_events= data['event_id'].nunique()\n",
    "total_events = len(data['event_id'])\n",
    "print(f'There are {unique_events} unique events out of {total_events} total events')\n",
    "print(f'There are {missing_events} missing events')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d777e3db",
   "metadata": {},
   "source": [
    "#### Investigation type\n",
    "\n",
    "We will keep this column\n",
    "- It has 2 values (Accident, Incident)\n",
    "- It has 0 missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8691ac76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#check for missing values\n",
    "print(data['investigation_type'].isna().sum())\n",
    "print(data['investigation_type'].nunique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f942784",
   "metadata": {},
   "source": [
    "#### Accident Number\n",
    "##### Observation\n",
    "The column has no missing values\n",
    "The column has 88863 unique values\n",
    "We will keep it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31745f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88863"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['accident_number'].isna().sum()\n",
    "data['accident_number'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c7d577",
   "metadata": {},
   "source": [
    "#### Event Date\n",
    "##### Observation\n",
    "We will normalize the dates so they are all uniform\n",
    "- We set the date format to year-month-day\n",
    "- The column has no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af6b5e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(data['event_date'])#y-m-day\n",
    "data['event_date'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414a38d1",
   "metadata": {},
   "source": [
    "#### Location & Country\n",
    "- We had 52 missing values that we filled with unknown\n",
    "- We will merge Us state codes with the location\n",
    "- We will also fill missing data in country with unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49d37609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load us_codes\n",
    "codes = r\"C:\\Users\\USER\\Documents\\moringa_school\\phase_1\\phase_1_project\\Data\\USState_Codes.csv\"\n",
    "us_codes = pd.read_csv(codes, encoding='latin1', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc90a511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        MOOSE CREEK, ID\n",
       "1         BRIDGEPORT, CA\n",
       "2          Saltville, VA\n",
       "3             EUREKA, CA\n",
       "4             Canton, OH\n",
       "              ...       \n",
       "88884      Annapolis, MD\n",
       "88885        Hampton, NH\n",
       "88886         Payson, AZ\n",
       "88887         Morgan, UT\n",
       "88888         Athens, GA\n",
       "Name: location, Length: 88889, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#standardize location and country using the above dataset\n",
    "state_dict= dict(zip(us_codes['US_State'].str.lower(),us_codes['Abbreviation']))\n",
    "data['location']=data['location'].str.lower().map(state_dict).fillna(data['location'])\n",
    "data['location'].fillna('unknown',inplace=True)\n",
    "abbrevs= us_codes['Abbreviation'].tolist()\n",
    "data['country']= data.apply(\n",
    "     lambda x: 'USA' if x['location'] in abbrevs else x['country'], axis=1\n",
    "                            )\n",
    "data['country'].fillna('unknown', inplace=True)\n",
    "data['location']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2a3676",
   "metadata": {},
   "source": [
    "### Make, Model & Amateur build\n",
    "\n",
    "Since the missing values are very small 1% we will fill the mode for categorical values and median for numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a86ba887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with <1% missing values: ['make', 'model', 'amateur_built']\n"
     ]
    }
   ],
   "source": [
    "#Fill median and mode for <1% missingness\n",
    "low_missing_cols = data.columns[(data.isna().sum() > 0) & (data.isna().sum() < 0.01 * len(data))]\n",
    "print(f\"Columns with <1% missing values: {list(low_missing_cols)}\")\n",
    "for col in low_missing_cols:\n",
    "    if data[col].dtype in ['object', 'category']:  # Categorical\n",
    "        data[col].fillna(data[col].mode()[0], inplace=True)\n",
    "    else:  # Numerical\n",
    "        data[col].fillna(data[col].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c824cec",
   "metadata": {},
   "source": [
    "#### Injuries\n",
    "\n",
    "Since total fatal injuries, total serious injuries, total minor injuries,injury severity and total uninjured have moderately high level of missingness, we will fill the missing values with unknown to avoid bias.\n",
    "Filling 0, will mean that no one had any sort of injury, yet we are not sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8d2dbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "injury_col=['total_fatal_injuries','total_serious_injuries','injury_severity','total_minor_injuries','total_uninjured']\n",
    "for col in injury_col:\n",
    "    if col in data.columns:\n",
    "        data[col].fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d531dbb",
   "metadata": {},
   "source": [
    "### aircraft damage, registration number, number of engines, engine type, purpose of flight, weather condition, report status\n",
    "\n",
    "We will also fill unknown for the missin values in the above columns.\n",
    "For columns  like registration number we cannot just imput any number like a median or median since it is a unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c04cba63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with >1000 and <30% missing values: ['aircraft_damage', 'registration_number', 'number_of_engines', 'engine_type', 'purpose_of_flight', 'weather_condition', 'report_status']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moderate_missing_cols = data.columns[(data.isna().sum() > 1000) & (data.isna().sum() < 0.3 * len(data))]\n",
    "moderate_missing_cols = [col for col in moderate_missing_cols if col not in retain]\n",
    "print(f\"Columns with >1000 and <30% missing values: {list(moderate_missing_cols)}\")\n",
    "[data[col].fillna('unknown', inplace=True) for col in moderate_missing_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a17db1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-6d002b8f799f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-23-6d002b8f799f>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Verify dataset is clean\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Verify dataset is clean\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4783ed72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
